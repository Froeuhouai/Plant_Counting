# -*- coding: utf-8 -*-
"""
Created on Sat Feb  6 14:17:38 2021

@author: eliot

Here we include the functions used to process the labelled images generated with
Unity. This processes the json captures of 1 field at 1 growth stage.

v1:
    - We compute the bounding box ourselve thanks to the Mesh bounds accessible
    within Unity

v2:
    - We Extract the pixel metric given in the lablling files generated by Unity
    Perception

v3:
    - We use the 2D bounding box given by Unity to count the number of pixles
    that were segmented for all plants.

"""
import os
import sys
import numpy as np
np.set_printoptions(threshold=sys.maxsize)

import matplotlib.pyplot as plt
import matplotlib.patches as patches

from PIL import Image
import json

os.chdir("../Utility")
import general_IO as gIO

viewport_annotation_id = "c0b4a22c-0420-4d9f-bafc-954b8f7b35a7"
boundingbox_annotation_id = "f9f22e05-443f-4602-a422-ebe4ea9b55cb"

weed_label = 5

def Produce_Adjusted_Position_Files( _path_position_file,
                                     _path_adjusted_position_files,
                                     _rows_real_angle,
                                     _path_input_rgb_img,
                                     _list_rgb_images,
                                     _pivot = np.array([960,540])
                                     ):
    
    posFile = open(_path_position_file+"/"+"/captures_000.json", 'r')
    
    posFile_deserialized = json.load(posFile)
    
    nb_capture = len(posFile_deserialized["captures"])
    
# =============================================================================
#     print(nb_capture)
#     print(posFile_deserialized)
# =============================================================================
    
    ViewPortValues = []
    for i in range(nb_capture):
        for _annot in posFile_deserialized["captures"][i]["annotations"]:
            if (_annot["annotation_definition"] == viewport_annotation_id):
                ViewPortValues += [_annot["values"]]
    
    #print(ViewPortValues)
    
    nb_imgs = len(_list_rgb_images)
    assert nb_imgs == len(ViewPortValues)
    
    _theta = np.deg2rad(_rows_real_angle)
    R = np.array([[np.cos(_theta), np.sin(_theta)],
                         [-np.sin(_theta),  np.cos(_theta)]])
    
    
    for i in range (nb_imgs):
        _img = Image.open(_path_input_rgb_img+\
                          "/" + _list_rgb_images[i])
        #_img_rot = _img.rotate(_rows_real_angle, expand=True)
        
        a = np.array([_img.width, 0])
        #b = np.array([0, 0])
        #offset to have only positives coordinates
        y_offset_p = (np.dot(R, a-_pivot))+_pivot
        x_offset_p = (np.dot(R, -_pivot))+_pivot
        
# =============================================================================
#         plt.figure()
#         plt.imshow(_img.rotate(_rows_real_angle, expand=True))
#         plt.scatter(x_offset_p[0]-x_offset_p[0],x_offset_p[1]-y_offset_p[1])
#         plt.scatter(y_offset_p[0]-x_offset_p[0],y_offset_p[1]-y_offset_p[1])
#         print(x_offset_p, y_offset_p)
# =============================================================================
        nb_plants = len(ViewPortValues[i])
        print(nb_plants)
        y_offset = y_offset_p[1]
        x_offset = x_offset_p[0]
        
        _adjusted_pos = []
        _x = []
        _y = []
        for j in range(nb_plants):
            #print(ViewPortValues[i][j])
            _screen_prop = np.array([ViewPortValues[i][j]["ViewPort"]["x"],
                                     ViewPortValues[i][j]["ViewPort"]["y"]])
            
            _rot_coord = np.dot(R, np.array([_screen_prop[0] *_img.width,
                                             (1-_screen_prop[1])*_img.height])-_pivot)+\
                        _pivot + np.array([-x_offset, -y_offset])
                        
                        
            _adjusted_pos  += [{"instance_id": ViewPortValues[i][j]["instance_id"],
                                "view_port_x": ViewPortValues[i][j]["ViewPort"]["x"],
                                "view_port_y": ViewPortValues[i][j]["ViewPort"]["y"],
                                "image_x": _screen_prop[0] *_img.width,
                                "image_y": (1-_screen_prop[1])*_img.height,
                                "rotated_x": _rot_coord[0],
                                "rotated_y": _rot_coord[1]}]
            
            _x.append(_rot_coord[0])
            _y.append(_rot_coord[1])
            
        #print(_adjusted_pos)
        
        gIO.check_make_directory(_path_adjusted_position_files)
        gIO.WriteJson(_path_adjusted_position_files, 
                      "Adjusted_plant_positions_"+_list_rgb_images[i].split(".")[0],
                      _adjusted_pos)
# =============================================================================
#         plt.figure()
#         plt.imshow(_img.rotate(_rows_real_angle, expand=True))
#         plt.scatter(_x, _y)
# =============================================================================

def Compute_Pixels_In_Plant_Bounding_Boxes(_path_input_position_files,
                                          _path_output_files,
                                          _path_input_Support_Images):
    
    """
    The bounding boxes from Unity Perception labelling.
    """
    
    posFile = open(_path_input_position_files+"/"+"/captures_000.json", 'r')
    
    posFile_deserialized = json.load(posFile)
    
    nb_capture = len(posFile_deserialized["captures"])
    
    BoundingBoxValues = []
    for i in range(nb_capture):
        for _annot in posFile_deserialized["captures"][i]["annotations"]:
            if (_annot["annotation_definition"] == boundingbox_annotation_id):
                BoundingBoxValues += [_annot["values"]]
    
    
    _list_support_images = os.listdir(_path_input_Support_Images)
    nb_imgs = len(_list_support_images)
    assert nb_imgs == len(BoundingBoxValues)
    
    gIO.check_make_directory(_path_output_files)
    
    for i in range(nb_imgs):
        print ("Processing Bounding Boxes of Image {0}/{1}".format(i+1, nb_imgs))
        
        _img = Image.open(_path_input_Support_Images+\
                          "/" + _list_support_images[i])
        
        _img_dict_bounding_box = BoundingBoxValues[i]
        
        selected_dict = []
        
        for _dict in _img_dict_bounding_box:    
            if (_dict["label_id"]!=weed_label):
                _dict["nb_pixels"]=Compute_Surface(_img, _dict)
                if (_dict["nb_pixels"]>0):
                    selected_dict += [_dict]
                    
        
        
        name = "Bounding_Boxes_"+_list_support_images[i].split(".")[0]
        file = open(_path_output_files+"/"+name+".json", "w")
        json.dump(selected_dict, file, indent = 2)
        file.close()
        
# =============================================================================
#         Show_Boxes(_img, _img_dict_bounding_box)
# =============================================================================

def Compute_Surface(_img, _dict_bounding_box):
        """
        Counts the number of white pixels in the area covered by one bounding box.
        """
        _img_array = np.array(_img)
        
        nb_contiguous_white_pixel = 0 #reset
        
        search_space_array = np.zeros((int(_dict_bounding_box["height"])+1,
                                       int(_dict_bounding_box["width"])+1))
        
        for _r in range(int(_dict_bounding_box["height"])+1):
            for _c in range(int(_dict_bounding_box["width"])+1):
                
                _x = int(_dict_bounding_box["x"]) + _c
                _y = int(_dict_bounding_box["y"]) + _r
                
                if (0<=_y<_img.height and 0<=_x<_img.width):
                    if _img_array[_y][_x][0] > 220:
                        nb_contiguous_white_pixel += 1
                        
                        search_space_array[_r][_c] = 1
                        
# =============================================================================
#         fig = plt.figure(figsize=(5,5),dpi=300)
#         ax = fig.add_subplot(111)
#         ax.imshow(search_space_array)
# =============================================================================
            
        return nb_contiguous_white_pixel

def Show_Boxes(_img,
               _img_dict_bounding_box):
    fig = plt.figure(figsize=(5,5),dpi=300)
    ax = fig.add_subplot(111)
    ax.imshow(_img)
    
    Show_Plant_Bounding_Boxes(ax,_img_dict_bounding_box)

def Show_Plant_Bounding_Boxes(_ax, _img_dict_bounding_box):
    for _dict in _img_dict_bounding_box:
        if _dict["label_id"]==5:
            _edc = "yellow"
        else:
            _edc = "green"
        rect = patches.Rectangle((_dict["x"], _dict["y"]),
                                 _dict["width"], _dict["height"],
                                 linewidth=1,
                                 edgecolor=_edc,
                                 facecolor='none')
        _ax.add_patch(rect)

if (__name__ == "__main__"):
# =============================================================================
#     Produce_Adjusted_Position_Files(
#             "D:/Projet/Unity/HDRP_PGoCF/Datasets/Monitoring/Series_9/2021_02_18_10_05/Dataset",
#             "D:/Projet/Unity/HDRP_PGoCF/Datasets/Monitoring/Series_9/2021_02_18_10_05"+"/Ouput_General/Output/Session_{0}".format(1)+"/Adjusted_Position_Files",
#             80,
#             "D:/Projet/Unity/HDRP_PGoCF/Datasets/Monitoring/Series_9/2021_02_18_10_05/RGB",
#             os.listdir("D:/Projet/Unity/HDRP_PGoCF/Datasets/Monitoring/Series_9/2021_02_18_10_05/RGB"))
# =============================================================================
    
    Compute_Pixels_In_Plant_Bounding_Boxes(
            "D:/Projet/Unity/HDRP_PGoCF/Datasets/Monitoring/Series_9/2021_02_18_17_43/Dataset",
            "D:/Projet/Unity/HDRP_PGoCF/Datasets/Monitoring/Series_9/2021_02_18_17_43/Ouput_General"+"/Output/Session_{0}".format(1)+"/Plant_Bounding_Boxes",
            "D:/Projet/Unity/HDRP_PGoCF/Datasets/Monitoring/Series_9/2021_02_18_17_43/Ouput_General"+"/Output/Session_{0}".format(1)+"/Otsu")
